{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_model",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1KEo7Lelw0V"
      },
      "source": [
        "###Copying the validation set from Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cFOuHES-ji1"
      },
      "source": [
        "!cp /content/drive/MyDrive/Deep_Learning/attentive_gan_derainment/validation_set/validation.zip /content"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH8vyVNF_AMe"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAC6klkE-06z"
      },
      "source": [
        "!unzip validation.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PEl2q4pGYrF"
      },
      "source": [
        "##Cloning the repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tFI16yD9e-F",
        "outputId": "d80e9d06-a7d4-4c71-df03-73100b6187ec"
      },
      "source": [
        "!git clone https://github.com/MaybeShewill-CV/attentive-gan-derainnet.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'attentive-gan-derainnet'...\n",
            "remote: Enumerating objects: 550, done.\u001b[K\n",
            "remote: Total 550 (delta 0), reused 0 (delta 0), pack-reused 550\u001b[K\n",
            "Receiving objects: 100% (550/550), 358.14 MiB | 32.84 MiB/s, done.\n",
            "Resolving deltas: 100% (259/259), done.\n",
            "Checking out files: 100% (53/53), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI_2RDF_9muP"
      },
      "source": [
        "%cd /content/attentive-gan-derainnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M206WO6AJWmp"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5Eimm2_xjtz"
      },
      "source": [
        "!pip install glog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuDb4D4G_Dli"
      },
      "source": [
        "###Mounting the VGG16 model from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SXJ0XnnIivx"
      },
      "source": [
        "!cp /content/drive/MyDrive/Deep_Learning/VGG16/vgg16.npy /content/attentive-gan-derainnet/data"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBCV3w5dDdIl"
      },
      "source": [
        "!mv /content/__init__.py /content/attentive-gan-derainnet/config"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgDUAhYWxYex"
      },
      "source": [
        "!mv /content/__init__.py /content/attentive-gan-derainnet/data_provider"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YLIcbrPAst1"
      },
      "source": [
        "###Removing previous example files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS1g_2LUTqUp"
      },
      "source": [
        "!rm -rf /content/attentive-gan-derainnet/data/training_data_example/clean_image/*"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srXtIFY3TxFI"
      },
      "source": [
        "!rm -rf /content/attentive-gan-derainnet/data/training_data_example/rain_image/*"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16rXcmIAAkYV"
      },
      "source": [
        "###Validation set\n",
        "***Copying the validaation set to the training folder***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfYdhVpuATrj"
      },
      "source": [
        "!cp /content/validation/rain_image/* /content/attentive-gan-derainnet/data/training_data_example/rain_image"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMoFVFYIATVN"
      },
      "source": [
        "!cp /content/validation/clean_image/* /content/attentive-gan-derainnet/data/training_data_example/clean_image"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDsb5mrX-1Lz"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h0YmJMSmHJT"
      },
      "source": [
        "***When running the data_feed_pipline.py file ensure that it is in the root directory to avoid failed import of packages error***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHc4Px3N9mx-",
        "outputId": "055ced0f-9d8a-4a42-c044-68dec84e45c0"
      },
      "source": [
        "!python data_feed_pipline.py --dataset_dir /content/attentive-gan-derainnet/data/training_data_example --tfrecords_dir TFRECORDS_SAVE_DIR"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I1003 17:23:08.832167 972 data_feed_pipline.py:220] Generate training example index file complete\n",
            "I1003 17:23:08.832420 972 data_feed_pipline.py:108] Generating training example tfrecords\n",
            "I1003 17:23:08.832705 972 tf_io_pipline_tools.py:65] Writing TFRECORDS_SAVE_DIR/train_0_54.tfrecords....\n",
            "W1003 17:23:08.832907 972 module_wrapper.py:139] From /content/attentive-gan-derainnet/data_provider/tf_io_pipline_tools.py:67: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "I1003 17:23:10.576322 972 tf_io_pipline_tools.py:105] Writing TFRECORDS_SAVE_DIR/train_0_54.tfrecords complete\n",
            "I1003 17:23:10.576620 972 data_feed_pipline.py:120] Generate training example tfrecords complete\n",
            "I1003 17:23:10.576694 972 data_feed_pipline.py:123] Generating validation example tfrecords\n",
            "I1003 17:23:10.576924 972 tf_io_pipline_tools.py:65] Writing TFRECORDS_SAVE_DIR/val_0_3.tfrecords....\n",
            "I1003 17:23:10.670134 972 tf_io_pipline_tools.py:105] Writing TFRECORDS_SAVE_DIR/val_0_3.tfrecords complete\n",
            "I1003 17:23:10.670415 972 data_feed_pipline.py:135] Generate validation example tfrecords complete\n",
            "I1003 17:23:10.670506 972 data_feed_pipline.py:138] Generating testing example tfrecords\n",
            "I1003 17:23:10.670755 972 tf_io_pipline_tools.py:65] Writing TFRECORDS_SAVE_DIR/test_0_7.tfrecords....\n",
            "I1003 17:23:10.888445 972 tf_io_pipline_tools.py:105] Writing TFRECORDS_SAVE_DIR/test_0_7.tfrecords complete\n",
            "I1003 17:23:10.888738 972 data_feed_pipline.py:150] Generate testing example tfrecords complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j6H-G_lmdHH"
      },
      "source": [
        "***Ensure the train_model.py is in the root directory to avoid failed import of packages error. Also change the number of epochs in the global_config.py file in the config folder.\n",
        "Ensure in the train_model.py the loading of the VGG16 model you add the parameter allow_pickle=True in the np.load() method.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nil2iiqtJc8Q",
        "outputId": "718bdd99-104a-4136-b729-fb4dfdd7afc3"
      },
      "source": [
        "!python train_model.py --dataset_dir /content/attentive-gan-derainnet/data/training_data_example"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I1003 17:25:12.544520 1031 utils.py:157] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W1003 17:25:12.934943 1031 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:Entity <function decode at 0x7fb9079544d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1003 17:25:12.974495 1031 ag_logging.py:146] Entity <function decode at 0x7fb9079544d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/data_provider/tf_io_pipline_tools.py:116: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W1003 17:25:12.974857 1031 module_wrapper.py:139] From /content/attentive-gan-derainnet/data_provider/tf_io_pipline_tools.py:116: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/data_provider/tf_io_pipline_tools.py:120: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W1003 17:25:12.975039 1031 module_wrapper.py:139] From /content/attentive-gan-derainnet/data_provider/tf_io_pipline_tools.py:120: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:Entity <function augment_for_train at 0x7fb907954440> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1003 17:25:13.003017 1031 ag_logging.py:146] Entity <function augment_for_train at 0x7fb907954440> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/data_provider/tf_io_pipline_tools.py:211: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.\n",
            "\n",
            "W1003 17:25:13.008065 1031 module_wrapper.py:139] From /content/attentive-gan-derainnet/data_provider/tf_io_pipline_tools.py:211: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:Entity <function normalize at 0x7fb907954680> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1003 17:25:13.039333 1031 ag_logging.py:146] Entity <function normalize at 0x7fb907954680> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/data_provider/data_feed_pipline.py:292: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "W1003 17:25:13.052934 1031 deprecation.py:323] From /content/attentive-gan-derainnet/data_provider/data_feed_pipline.py:292: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "VGG16 Network init complete\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/derain_drop_net.py:39: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W1003 17:25:13.159373 1031 module_wrapper.py:139] From /content/attentive-gan-derainnet/attentive_gan_model/derain_drop_net.py:39: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:71: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W1003 17:25:13.163195 1031 module_wrapper.py:139] From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:71: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/attentive_gan_net.py:201: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
            "\n",
            "W1003 17:25:14.070916 1031 module_wrapper.py:139] From /content/attentive-gan-derainnet/attentive_gan_model/attentive_gan_net.py:201: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1003 17:25:14.080155 1031 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/attentive_gan_net.py:327: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "W1003 17:25:14.148431 1031 module_wrapper.py:139] From /content/attentive-gan-derainnet/attentive_gan_model/attentive_gan_net.py:327: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:402: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "W1003 17:25:14.439682 1031 deprecation.py:323] From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:402: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/convolutional.py:1279: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1003 17:25:14.440721 1031 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/convolutional.py:1279: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:167: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "W1003 17:25:14.466609 1031 module_wrapper.py:139] From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:167: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:143: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W1003 17:25:14.636741 1031 module_wrapper.py:139] From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:143: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:304: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W1003 17:25:14.938248 1031 deprecation.py:323] From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:304: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/discriminative_net.py:123: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W1003 17:25:15.062875 1031 module_wrapper.py:139] From /content/attentive-gan-derainnet/attentive_gan_model/discriminative_net.py:123: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From train_model.py:183: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W1003 17:25:16.450302 1031 module_wrapper.py:139] From train_model.py:183: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From train_model.py:191: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W1003 17:25:16.453685 1031 module_wrapper.py:139] From train_model.py:191: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From train_model.py:195: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W1003 17:25:16.460001 1031 module_wrapper.py:139] From train_model.py:195: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From train_model.py:195: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W1003 17:25:16.460331 1031 module_wrapper.py:139] From train_model.py:195: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From train_model.py:197: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W1003 17:25:16.460583 1031 module_wrapper.py:139] From train_model.py:197: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From train_model.py:199: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "W1003 17:25:17.082627 1031 module_wrapper.py:139] From train_model.py:199: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From train_model.py:204: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W1003 17:25:20.172709 1031 module_wrapper.py:139] From train_model.py:204: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From train_model.py:217: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W1003 17:25:20.414204 1031 module_wrapper.py:139] From train_model.py:217: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From train_model.py:228: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "W1003 17:25:20.423346 1031 module_wrapper.py:139] From train_model.py:228: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From train_model.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W1003 17:25:20.424893 1031 module_wrapper.py:139] From train_model.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From train_model.py:241: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W1003 17:25:20.425204 1031 module_wrapper.py:139] From train_model.py:241: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-10-03 17:25:20.435597: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-10-03 17:25:20.435870: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5556217bad80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-10-03 17:25:20.435905: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-10-03 17:25:20.440045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-10-03 17:25:20.454451: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-10-03 17:25:20.454495: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (82edbb7907c2): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From train_model.py:243: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "W1003 17:25:20.454976 1031 module_wrapper.py:139] From train_model.py:243: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "I1003 17:25:21.145504 1031 train_model.py:249] Global configuration is as follows:\n",
            "I1003 17:25:21.145702 1031 train_model.py:250] {'TRAIN': {'EPOCHS': 100, 'LEARNING_RATE': 0.0002, 'GPU_MEMORY_FRACTION': 0.95, 'TF_ALLOW_GROWTH': True, 'BATCH_SIZE': 1, 'IMG_HEIGHT': 256, 'IMG_WIDTH': 376, 'CROP_IMG_HEIGHT': 240, 'CROP_IMG_WIDTH': 360, 'CPU_MULTI_PROCESS_NUMS': 6, 'GPU_NUM': 2}, 'TEST': {'GPU_MEMORY_FRACTION': 0.8, 'TF_ALLOW_GROWTH': False, 'BATCH_SIZE': 1, 'IMG_HEIGHT': 240, 'IMG_WIDTH': 360}}\n",
            "I1003 17:25:21.145906 1031 train_model.py:254] Training from scratch\n",
            "WARNING:tensorflow:From train_model.py:255: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "W1003 17:25:21.146090 1031 module_wrapper.py:139] From train_model.py:255: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From train_model.py:268: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "W1003 17:25:26.227263 1031 module_wrapper.py:139] From train_model.py:268: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "2021-10-03 17:25:56.262124: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1105920000 exceeds 10% of system memory.\n",
            "tcmalloc: large alloc 1105920000 bytes == 0x55575d172000 @  0x7fb96bdb4b6b 0x7fb96bdd4379 0x7fb9225b5467 0x7fb9223a2c4f 0x7fb92226827b 0x7fb92222dc66 0x7fb922230971 0x7fb92aa7ad4a 0x7fb9224e6c56 0x7fb9224d92a5 0x7fb9225973a9 0x7fb922594a78 0x7fb96a6b46df 0x7fb96bb876db 0x7fb96acbc71f\n",
            "2021-10-03 17:25:56.963050: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1105920000 exceeds 10% of system memory.\n",
            "2021-10-03 17:25:57.747212: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1105920000 exceeds 10% of system memory.\n",
            "2021-10-03 17:25:59.945288: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1105920000 exceeds 10% of system memory.\n",
            "2021-10-03 17:26:01.763204: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1105920000 exceeds 10% of system memory.\n",
            "I1003 17:26:31.118703 1031 train_model.py:292] Epoch_Train: 0 D_loss: 2.38006 G_loss: 9.65433 SSIM: 0.23468 PSNR: 12.45168 Cost_time: 62.20627s\n",
            "I1003 17:26:42.219845 1031 train_model.py:302] Epoch_Val: 0 D_loss: 2.32864 G_loss: 13.05419 SSIM: 0.11794 PSNR: 7.51948 Cost_time: 62.20627s\n",
            "I1003 17:27:37.790751 1031 train_model.py:292] Epoch_Train: 1 D_loss: 2.41606 G_loss: 14.78436 SSIM: 0.10180 PSNR: 10.53871 Cost_time: 54.47339s\n",
            "I1003 17:28:31.008537 1031 train_model.py:292] Epoch_Train: 2 D_loss: 7.90582 G_loss: 8.97055 SSIM: 0.61056 PSNR: 10.08719 Cost_time: 53.21752s\n",
            "I1003 17:29:24.097085 1031 train_model.py:292] Epoch_Train: 3 D_loss: 0.51608 G_loss: 12.11747 SSIM: 0.14791 PSNR: 7.96379 Cost_time: 53.08805s\n",
            "I1003 17:30:17.159043 1031 train_model.py:292] Epoch_Train: 4 D_loss: 2.25172 G_loss: 11.26028 SSIM: 0.15279 PSNR: 12.36683 Cost_time: 53.06155s\n",
            "I1003 17:31:10.408497 1031 train_model.py:292] Epoch_Train: 5 D_loss: 1.77111 G_loss: 5.68867 SSIM: 0.30598 PSNR: 16.14186 Cost_time: 53.24896s\n",
            "I1003 17:32:03.321169 1031 train_model.py:292] Epoch_Train: 6 D_loss: 11.26774 G_loss: 11.84476 SSIM: 0.32818 PSNR: 11.96307 Cost_time: 52.91228s\n",
            "I1003 17:32:56.754276 1031 train_model.py:292] Epoch_Train: 7 D_loss: 14.73417 G_loss: 7.26126 SSIM: 0.43600 PSNR: 10.46206 Cost_time: 53.43267s\n",
            "I1003 17:33:49.992425 1031 train_model.py:292] Epoch_Train: 8 D_loss: 17.15856 G_loss: 3.41741 SSIM: 0.57293 PSNR: 16.00480 Cost_time: 53.23789s\n",
            "I1003 17:34:42.680062 1031 train_model.py:292] Epoch_Train: 9 D_loss: 13.71003 G_loss: 8.94960 SSIM: 0.43215 PSNR: 12.17321 Cost_time: 52.68718s\n",
            "I1003 17:35:39.977463 1031 train_model.py:292] Epoch_Train: 10 D_loss: 17.00376 G_loss: 5.12992 SSIM: 0.60436 PSNR: 20.10598 Cost_time: 57.29715s\n",
            "I1003 17:36:32.804432 1031 train_model.py:292] Epoch_Train: 11 D_loss: 7.64520 G_loss: 7.63300 SSIM: 0.44591 PSNR: 14.32194 Cost_time: 52.82627s\n",
            "I1003 17:37:25.971099 1031 train_model.py:292] Epoch_Train: 12 D_loss: 5.36390 G_loss: 5.15980 SSIM: 0.34796 PSNR: 14.87092 Cost_time: 53.16622s\n",
            "I1003 17:38:20.333678 1031 train_model.py:292] Epoch_Train: 13 D_loss: 1.92761 G_loss: 9.50322 SSIM: 0.43934 PSNR: 12.78726 Cost_time: 54.36207s\n",
            "I1003 17:39:13.397915 1031 train_model.py:292] Epoch_Train: 14 D_loss: 2.25296 G_loss: 5.41476 SSIM: 0.44105 PSNR: 14.34954 Cost_time: 53.06395s\n",
            "I1003 17:40:06.416556 1031 train_model.py:292] Epoch_Train: 15 D_loss: 3.36746 G_loss: 7.47376 SSIM: 0.45077 PSNR: 13.13172 Cost_time: 53.01817s\n",
            "I1003 17:40:59.387254 1031 train_model.py:292] Epoch_Train: 16 D_loss: 1.68621 G_loss: 7.04542 SSIM: 0.39231 PSNR: 13.41278 Cost_time: 52.97026s\n",
            "I1003 17:41:52.429846 1031 train_model.py:292] Epoch_Train: 17 D_loss: 1.48970 G_loss: 6.43199 SSIM: 0.46873 PSNR: 11.75110 Cost_time: 53.04233s\n",
            "I1003 17:42:45.302505 1031 train_model.py:292] Epoch_Train: 18 D_loss: 2.12721 G_loss: 6.97047 SSIM: 0.51628 PSNR: 11.80305 Cost_time: 52.87220s\n",
            "I1003 17:43:38.310936 1031 train_model.py:292] Epoch_Train: 19 D_loss: 0.95012 G_loss: 6.55640 SSIM: 0.49889 PSNR: 13.27849 Cost_time: 53.00814s\n",
            "I1003 17:44:31.217231 1031 train_model.py:292] Epoch_Train: 20 D_loss: 1.39022 G_loss: 2.92362 SSIM: 0.54130 PSNR: 15.66459 Cost_time: 52.90558s\n",
            "I1003 17:45:27.147816 1031 train_model.py:292] Epoch_Train: 21 D_loss: 1.64332 G_loss: 4.98447 SSIM: 0.57614 PSNR: 13.86193 Cost_time: 55.93022s\n",
            "I1003 17:46:20.514338 1031 train_model.py:292] Epoch_Train: 22 D_loss: 1.79061 G_loss: 6.46995 SSIM: 0.38259 PSNR: 13.39024 Cost_time: 53.36613s\n",
            "I1003 17:47:13.703406 1031 train_model.py:292] Epoch_Train: 23 D_loss: 1.56872 G_loss: 6.39104 SSIM: 0.43931 PSNR: 13.21134 Cost_time: 53.18882s\n",
            "I1003 17:48:06.973448 1031 train_model.py:292] Epoch_Train: 24 D_loss: 1.40541 G_loss: 5.86290 SSIM: 0.44626 PSNR: 14.52841 Cost_time: 53.26956s\n",
            "I1003 17:48:59.813414 1031 train_model.py:292] Epoch_Train: 25 D_loss: 1.13001 G_loss: 8.69807 SSIM: 0.46135 PSNR: 15.17151 Cost_time: 52.83951s\n",
            "I1003 17:49:53.573921 1031 train_model.py:292] Epoch_Train: 26 D_loss: 1.48711 G_loss: 4.47439 SSIM: 0.57772 PSNR: 15.38978 Cost_time: 53.75998s\n",
            "I1003 17:50:47.695409 1031 train_model.py:292] Epoch_Train: 27 D_loss: 1.97821 G_loss: 5.96256 SSIM: 0.47757 PSNR: 15.11002 Cost_time: 54.12124s\n",
            "I1003 17:51:40.938758 1031 train_model.py:292] Epoch_Train: 28 D_loss: 1.53213 G_loss: 3.35726 SSIM: 0.52757 PSNR: 19.04882 Cost_time: 53.24289s\n",
            "I1003 17:52:33.994061 1031 train_model.py:292] Epoch_Train: 29 D_loss: 1.07424 G_loss: 2.33175 SSIM: 0.74937 PSNR: 22.28903 Cost_time: 53.05507s\n",
            "I1003 17:53:27.272080 1031 train_model.py:292] Epoch_Train: 30 D_loss: 1.58823 G_loss: 1.54606 SSIM: 0.79838 PSNR: 28.75271 Cost_time: 53.27637s\n",
            "I1003 17:54:20.308770 1031 train_model.py:292] Epoch_Train: 31 D_loss: 2.69390 G_loss: 7.36915 SSIM: 0.54841 PSNR: 18.67689 Cost_time: 53.03628s\n",
            "I1003 17:55:17.662976 1031 train_model.py:292] Epoch_Train: 32 D_loss: 1.43100 G_loss: 2.81905 SSIM: 0.42223 PSNR: 21.80396 Cost_time: 57.35371s\n",
            "I1003 17:56:12.564207 1031 train_model.py:292] Epoch_Train: 33 D_loss: 1.73413 G_loss: 6.01943 SSIM: 0.46878 PSNR: 17.65276 Cost_time: 54.90083s\n",
            "I1003 17:57:06.184859 1031 train_model.py:292] Epoch_Train: 34 D_loss: 1.44984 G_loss: 4.91432 SSIM: 0.68475 PSNR: 17.77444 Cost_time: 53.62039s\n",
            "I1003 17:57:59.089163 1031 train_model.py:292] Epoch_Train: 35 D_loss: 2.28027 G_loss: 5.43000 SSIM: 0.58365 PSNR: 18.29261 Cost_time: 52.90368s\n",
            "I1003 17:58:52.509402 1031 train_model.py:292] Epoch_Train: 36 D_loss: 1.77016 G_loss: 4.94163 SSIM: 0.58501 PSNR: 17.23229 Cost_time: 53.41981s\n",
            "I1003 17:59:45.630965 1031 train_model.py:292] Epoch_Train: 37 D_loss: 1.51707 G_loss: 1.64384 SSIM: 0.74490 PSNR: 22.28432 Cost_time: 53.12109s\n",
            "I1003 18:00:39.160610 1031 train_model.py:292] Epoch_Train: 38 D_loss: 1.56573 G_loss: 4.98010 SSIM: 0.58867 PSNR: 19.32437 Cost_time: 53.52906s\n",
            "I1003 18:01:32.425713 1031 train_model.py:292] Epoch_Train: 39 D_loss: 1.26087 G_loss: 2.63525 SSIM: 0.67044 PSNR: 19.79386 Cost_time: 53.26466s\n",
            "I1003 18:02:25.588660 1031 train_model.py:292] Epoch_Train: 40 D_loss: 1.44413 G_loss: 4.22169 SSIM: 0.70542 PSNR: 19.30845 Cost_time: 53.16249s\n",
            "I1003 18:03:19.364032 1031 train_model.py:292] Epoch_Train: 41 D_loss: 1.47660 G_loss: 2.79131 SSIM: 0.59617 PSNR: 20.66717 Cost_time: 53.77481s\n",
            "I1003 18:04:13.034847 1031 train_model.py:292] Epoch_Train: 42 D_loss: 1.29329 G_loss: 3.52968 SSIM: 0.63145 PSNR: 20.88011 Cost_time: 53.67033s\n",
            "I1003 18:05:06.561396 1031 train_model.py:292] Epoch_Train: 43 D_loss: 1.65986 G_loss: 3.23886 SSIM: 0.68340 PSNR: 19.53683 Cost_time: 53.52606s\n",
            "I1003 18:06:05.411762 1031 train_model.py:292] Epoch_Train: 44 D_loss: 1.40406 G_loss: 2.34728 SSIM: 0.61570 PSNR: 20.06872 Cost_time: 58.85009s\n",
            "I1003 18:06:58.549118 1031 train_model.py:292] Epoch_Train: 45 D_loss: 1.32958 G_loss: 6.23374 SSIM: 0.60399 PSNR: 15.32650 Cost_time: 53.13686s\n",
            "I1003 18:07:53.452012 1031 train_model.py:292] Epoch_Train: 46 D_loss: 1.36468 G_loss: 5.75309 SSIM: 0.61797 PSNR: 17.70910 Cost_time: 54.90242s\n",
            "I1003 18:08:47.317238 1031 train_model.py:292] Epoch_Train: 47 D_loss: 1.52511 G_loss: 3.61429 SSIM: 0.72196 PSNR: 20.08751 Cost_time: 53.86450s\n",
            "I1003 18:09:41.006377 1031 train_model.py:292] Epoch_Train: 48 D_loss: 1.26206 G_loss: 2.73268 SSIM: 0.77107 PSNR: 20.84754 Cost_time: 53.68874s\n",
            "I1003 18:10:34.138000 1031 train_model.py:292] Epoch_Train: 49 D_loss: 1.23943 G_loss: 5.07467 SSIM: 0.55966 PSNR: 15.88984 Cost_time: 53.13139s\n",
            "I1003 18:11:27.732760 1031 train_model.py:292] Epoch_Train: 50 D_loss: 1.59213 G_loss: 3.54062 SSIM: 0.62272 PSNR: 17.50273 Cost_time: 53.59418s\n",
            "I1003 18:12:20.860607 1031 train_model.py:292] Epoch_Train: 51 D_loss: 1.48962 G_loss: 7.28801 SSIM: 0.45231 PSNR: 17.99140 Cost_time: 53.12738s\n",
            "I1003 18:13:14.408326 1031 train_model.py:292] Epoch_Train: 52 D_loss: 1.40482 G_loss: 2.84340 SSIM: 0.73301 PSNR: 20.13960 Cost_time: 53.54729s\n",
            "I1003 18:14:10.554263 1031 train_model.py:292] Epoch_Train: 53 D_loss: 2.62563 G_loss: 5.42529 SSIM: 0.60476 PSNR: 17.71657 Cost_time: 56.14536s\n",
            "I1003 18:15:03.779958 1031 train_model.py:292] Epoch_Train: 54 D_loss: 1.99763 G_loss: 6.09401 SSIM: 0.60559 PSNR: 18.73109 Cost_time: 53.22522s\n",
            "I1003 18:16:02.835659 1031 train_model.py:292] Epoch_Train: 55 D_loss: 1.33702 G_loss: 3.75384 SSIM: 0.66358 PSNR: 19.75256 Cost_time: 59.05526s\n",
            "I1003 18:16:56.423729 1031 train_model.py:292] Epoch_Train: 56 D_loss: 1.46118 G_loss: 4.67563 SSIM: 0.67992 PSNR: 18.31368 Cost_time: 53.58733s\n",
            "I1003 18:17:49.888168 1031 train_model.py:292] Epoch_Train: 57 D_loss: 1.38197 G_loss: 2.45314 SSIM: 0.64680 PSNR: 21.70295 Cost_time: 53.46417s\n",
            "I1003 18:18:43.033652 1031 train_model.py:292] Epoch_Train: 58 D_loss: 1.37329 G_loss: 2.02185 SSIM: 0.76163 PSNR: 22.32360 Cost_time: 53.14508s\n",
            "I1003 18:19:37.479010 1031 train_model.py:292] Epoch_Train: 59 D_loss: 1.39249 G_loss: 5.82507 SSIM: 0.57857 PSNR: 16.35058 Cost_time: 54.44510s\n",
            "I1003 18:20:31.676617 1031 train_model.py:292] Epoch_Train: 60 D_loss: 1.40001 G_loss: 1.89097 SSIM: 0.68275 PSNR: 22.31416 Cost_time: 54.19731s\n",
            "I1003 18:21:25.827853 1031 train_model.py:292] Epoch_Train: 61 D_loss: 1.60434 G_loss: 4.76928 SSIM: 0.60235 PSNR: 16.89358 Cost_time: 54.15077s\n",
            "I1003 18:22:19.606211 1031 train_model.py:292] Epoch_Train: 62 D_loss: 1.34099 G_loss: 4.64296 SSIM: 0.56628 PSNR: 18.02740 Cost_time: 53.77777s\n",
            "I1003 18:23:13.741605 1031 train_model.py:292] Epoch_Train: 63 D_loss: 1.59142 G_loss: 3.22352 SSIM: 0.72714 PSNR: 21.87959 Cost_time: 54.13514s\n",
            "I1003 18:24:07.205047 1031 train_model.py:292] Epoch_Train: 64 D_loss: 1.30269 G_loss: 5.55072 SSIM: 0.64556 PSNR: 17.79465 Cost_time: 53.46298s\n",
            "I1003 18:25:00.992470 1031 train_model.py:292] Epoch_Train: 65 D_loss: 1.40346 G_loss: 1.44054 SSIM: 0.86729 PSNR: 21.34420 Cost_time: 53.78686s\n",
            "I1003 18:25:59.491814 1031 train_model.py:292] Epoch_Train: 66 D_loss: 1.44506 G_loss: 2.42334 SSIM: 0.79680 PSNR: 21.93305 Cost_time: 58.49907s\n",
            "I1003 18:26:54.037631 1031 train_model.py:292] Epoch_Train: 67 D_loss: 1.41615 G_loss: 5.15862 SSIM: 0.62550 PSNR: 19.01962 Cost_time: 54.54553s\n",
            "I1003 18:27:47.666403 1031 train_model.py:292] Epoch_Train: 68 D_loss: 1.40715 G_loss: 6.65882 SSIM: 0.57687 PSNR: 18.52303 Cost_time: 53.62723s\n",
            "I1003 18:28:41.002423 1031 train_model.py:292] Epoch_Train: 69 D_loss: 1.33526 G_loss: 4.46680 SSIM: 0.60491 PSNR: 15.64921 Cost_time: 53.33575s\n",
            "I1003 18:29:34.735881 1031 train_model.py:292] Epoch_Train: 70 D_loss: 1.33327 G_loss: 5.82162 SSIM: 0.53123 PSNR: 15.12399 Cost_time: 53.73316s\n",
            "I1003 18:30:28.313643 1031 train_model.py:292] Epoch_Train: 71 D_loss: 1.47476 G_loss: 4.85674 SSIM: 0.64552 PSNR: 18.96931 Cost_time: 53.57710s\n",
            "I1003 18:31:22.103136 1031 train_model.py:292] Epoch_Train: 72 D_loss: 1.36676 G_loss: 3.95706 SSIM: 0.65535 PSNR: 19.51043 Cost_time: 53.78922s\n",
            "I1003 18:32:15.438255 1031 train_model.py:292] Epoch_Train: 73 D_loss: 1.24210 G_loss: 3.26335 SSIM: 0.65548 PSNR: 17.88307 Cost_time: 53.33487s\n",
            "I1003 18:33:09.121706 1031 train_model.py:292] Epoch_Train: 74 D_loss: 1.19900 G_loss: 4.28841 SSIM: 0.61968 PSNR: 16.31878 Cost_time: 53.68282s\n",
            "I1003 18:34:02.633102 1031 train_model.py:292] Epoch_Train: 75 D_loss: 1.35045 G_loss: 1.38778 SSIM: 0.77187 PSNR: 24.59425 Cost_time: 53.51092s\n",
            "I1003 18:34:56.094919 1031 train_model.py:292] Epoch_Train: 76 D_loss: 1.26475 G_loss: 4.25799 SSIM: 0.62736 PSNR: 16.33373 Cost_time: 53.46152s\n",
            "I1003 18:35:53.822240 1031 train_model.py:292] Epoch_Train: 77 D_loss: 1.18080 G_loss: 5.15346 SSIM: 0.64976 PSNR: 18.07857 Cost_time: 57.72670s\n",
            "I1003 18:36:49.109750 1031 train_model.py:292] Epoch_Train: 78 D_loss: 0.99438 G_loss: 4.65690 SSIM: 0.55939 PSNR: 13.41132 Cost_time: 55.28449s\n",
            "I1003 18:37:42.307522 1031 train_model.py:292] Epoch_Train: 79 D_loss: 1.18077 G_loss: 3.70434 SSIM: 0.69993 PSNR: 18.80326 Cost_time: 53.19738s\n",
            "I1003 18:38:35.933549 1031 train_model.py:292] Epoch_Train: 80 D_loss: 1.23952 G_loss: 3.88139 SSIM: 0.64723 PSNR: 18.28895 Cost_time: 53.62577s\n",
            "I1003 18:39:29.339405 1031 train_model.py:292] Epoch_Train: 81 D_loss: 1.21073 G_loss: 2.12507 SSIM: 0.62534 PSNR: 20.34254 Cost_time: 53.40541s\n",
            "I1003 18:40:22.438277 1031 train_model.py:292] Epoch_Train: 82 D_loss: 1.39986 G_loss: 2.70836 SSIM: 0.64345 PSNR: 19.46704 Cost_time: 53.09841s\n",
            "I1003 18:41:15.610637 1031 train_model.py:292] Epoch_Train: 83 D_loss: 1.60195 G_loss: 5.06477 SSIM: 0.67617 PSNR: 17.92158 Cost_time: 53.17181s\n",
            "I1003 18:42:09.328162 1031 train_model.py:292] Epoch_Train: 84 D_loss: 1.59328 G_loss: 3.59223 SSIM: 0.75823 PSNR: 19.00781 Cost_time: 53.71712s\n",
            "I1003 18:43:02.666225 1031 train_model.py:292] Epoch_Train: 85 D_loss: 1.35662 G_loss: 2.17666 SSIM: 0.71559 PSNR: 21.21280 Cost_time: 53.33769s\n",
            "I1003 18:43:56.591628 1031 train_model.py:292] Epoch_Train: 86 D_loss: 1.28433 G_loss: 4.11840 SSIM: 0.69926 PSNR: 19.72083 Cost_time: 53.92513s\n",
            "I1003 18:44:49.782034 1031 train_model.py:292] Epoch_Train: 87 D_loss: 1.32809 G_loss: 6.58030 SSIM: 0.51092 PSNR: 19.53946 Cost_time: 53.18996s\n",
            "I1003 18:45:43.162592 1031 train_model.py:292] Epoch_Train: 88 D_loss: 1.46264 G_loss: 4.78159 SSIM: 0.68050 PSNR: 19.18730 Cost_time: 53.38016s\n",
            "I1003 18:46:42.134544 1031 train_model.py:292] Epoch_Train: 89 D_loss: 1.39064 G_loss: 3.33817 SSIM: 0.77313 PSNR: 19.74110 Cost_time: 58.97169s\n",
            "I1003 18:47:34.892029 1031 train_model.py:292] Epoch_Train: 90 D_loss: 1.42115 G_loss: 1.42666 SSIM: 0.78160 PSNR: 23.65398 Cost_time: 52.75690s\n",
            "I1003 18:48:27.679230 1031 train_model.py:292] Epoch_Train: 91 D_loss: 1.28220 G_loss: 5.44839 SSIM: 0.66391 PSNR: 15.93235 Cost_time: 52.78678s\n",
            "I1003 18:49:21.109794 1031 train_model.py:292] Epoch_Train: 92 D_loss: 1.34484 G_loss: 4.44026 SSIM: 0.59301 PSNR: 19.65261 Cost_time: 53.43030s\n",
            "I1003 18:50:14.370233 1031 train_model.py:292] Epoch_Train: 93 D_loss: 1.38707 G_loss: 3.15200 SSIM: 0.69157 PSNR: 18.88285 Cost_time: 53.25997s\n",
            "I1003 18:51:07.132899 1031 train_model.py:292] Epoch_Train: 94 D_loss: 1.36944 G_loss: 2.70929 SSIM: 0.74574 PSNR: 19.38767 Cost_time: 52.76229s\n",
            "I1003 18:52:00.486333 1031 train_model.py:292] Epoch_Train: 95 D_loss: 1.43183 G_loss: 4.92253 SSIM: 0.64907 PSNR: 18.20406 Cost_time: 53.35288s\n",
            "I1003 18:52:53.333805 1031 train_model.py:292] Epoch_Train: 96 D_loss: 1.36453 G_loss: 2.32129 SSIM: 0.67931 PSNR: 21.71943 Cost_time: 52.84721s\n",
            "I1003 18:53:46.399421 1031 train_model.py:292] Epoch_Train: 97 D_loss: 1.37692 G_loss: 1.86323 SSIM: 0.63852 PSNR: 20.43437 Cost_time: 53.06517s\n",
            "I1003 18:54:39.802885 1031 train_model.py:292] Epoch_Train: 98 D_loss: 1.35921 G_loss: 3.31799 SSIM: 0.69631 PSNR: 20.70909 Cost_time: 53.40288s\n",
            "I1003 18:55:33.227134 1031 train_model.py:292] Epoch_Train: 99 D_loss: 1.39356 G_loss: 2.79449 SSIM: 0.73248 PSNR: 22.16128 Cost_time: 53.42401s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFhEXILm-xrZ"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTmTvu1lhYtu"
      },
      "source": [
        "#removing the previous examples in the test folder\n",
        "!rm -rf /content/attentive-gan-derainnet/data/test_data/*"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgRZB7ZE9zfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b968aba8-fbf6-4980-a4b0-344e39ae2fbf"
      },
      "source": [
        "!python test_model.py --weights_path model/derain_gan/derain_gan_2021-10-03-17-25-20.ckpt-0 --image_path data/test_data/test_1.png"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From test_model.py:87: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "VGG16 Network init complete\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/derain_drop_net.py:84: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:71: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:402: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/convolutional.py:1279: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/attentive-gan-derainnet/attentive_gan_model/cnn_basenet.py:167: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From test_model.py:110: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From test_model.py:115: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-10-03 19:03:54.688112: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-10-03 19:03:54.688324: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56326ab3c680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-10-03 19:03:54.688360: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-10-03 19:03:54.690626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-10-03 19:03:54.705136: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-10-03 19:03:54.705179: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (82edbb7907c2): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From test_model.py:117: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62pqzLDlF8xb"
      },
      "source": [
        "###Exporting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRH1NFoC9zn6"
      },
      "source": [
        "!python export_tf_saved_model.py --export_dir model/derain_gan_my_saved_model  --ckpt_path model/derain_gan/derain_gan.ckpt-100000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIZe6lfnUpLk",
        "outputId": "b7fd06c1-67bc-460b-870c-897609673a13"
      },
      "source": [
        "%cd /content/attentive-gan-derainnet/data/training_data_example/rain_image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/attentive-gan-derainnet/data/training_data_example/rain_image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiM2Xh5HTNyx"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtuHOQfRTN7-"
      },
      "source": [
        "path = '/content/hazy.mp4'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEOS954qTN_W"
      },
      "source": [
        "#getting frames out of the dehazed video into the images folder\n",
        "vidcap = cv2.VideoCapture(path)\n",
        "def getFrame(sec):\n",
        "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
        "    hasFrames,image = vidcap.read()\n",
        "    if hasFrames:\n",
        "        cv2.imwrite(str(count)+\"_rain.png\", image)\n",
        "    return hasFrames\n",
        "sec = 0\n",
        "frameRate = 1\n",
        "count=1\n",
        "success = getFrame(sec)\n",
        "while success:\n",
        "    count = count + 1\n",
        "    sec = sec + frameRate\n",
        "    sec = round(sec, 2)\n",
        "    success = getFrame(sec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6RdDBSJlMCN"
      },
      "source": [
        "###Transfering the model to Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJdRAIAZlLdF"
      },
      "source": [
        "!mv /content/attentive-gan-derainnet /content/drive/MyDrive/Deep_Learning/attentive_gan_derainment"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}